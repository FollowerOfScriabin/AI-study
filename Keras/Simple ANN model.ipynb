{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@FollowerOfScriabin\n",
    "\n",
    "Reference : https://github.com/jskDr/keraspp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "#dir(models.Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution modeling, function type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_model_func(Nin,Nh,Nout):\n",
    "    x = layers.Input(shape=(Nin,))\n",
    "    h = layers.Activation('relu')(layers.Dense(Nh)(x))\n",
    "    y = layers.Activation('softmax')(layers.Dense(Nout)(h))\n",
    "    model = models.Model(x,y)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence modeling, function type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_seq_func(Nin,Nh,Nout):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(Nh, activation='relu',input_shape=(Nin,)))\n",
    "    model.add(layers.Dense(Nout,activation='softmax'))\n",
    "    moel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution modeling, class type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN_model(models.Model):\n",
    "    def __init__(self,Nin,Nh,Nout):\n",
    "        hidden = layers.Dense(Nh)\n",
    "        # if multi-layer:\n",
    "        # Nh = [a,b,c]\n",
    "        # hidden_layer = []\n",
    "        # for n in Nh:\n",
    "        # hidden_layer.append(layers.Dense(n))\n",
    "        output = layers.Dense(Nout)\n",
    "        relu = layers.Activation('relu')\n",
    "        softmax = layers.Activation('softmax')\n",
    "        x = layers.Input(shape=(Nin,))\n",
    "        h = relu(hidden(x))\n",
    "        y = softmax(output(h))\n",
    "        super().__init__(x, y)\n",
    "        self.compile(loss='categorical_crossentropy',\n",
    "                     optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential modeling, class type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN_seq(models.Sequential):\n",
    "    def __init__(self,Nin,Nh,Nout):\n",
    "        super().__init__()\n",
    "        self.add(layers.Dense(Nh,activation='relu',input_shape=(Nin,)))\n",
    "        self.add(layers.Dense(Nout,activation='softmax'))\n",
    "        self.compile(loss='categorical_crossentropy',\n",
    "                     optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import datasets\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Data_func():\n",
    "    (X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "    Y_train = np_utils.to_categorical(y_train)\n",
    "    Y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "    L, W, H = X_train.shape\n",
    "    X_train = X_train.reshape(-1, W * H)\n",
    "    X_test = X_test.reshape(-1, W * H)\n",
    "\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "\n",
    "    return (X_train, Y_train), (X_test, Y_test)\n",
    "\n",
    "def plot_acc(history, title=None):\n",
    "    if not isinstance(history, dict):\n",
    "        history = history.history\n",
    "\n",
    "    plt.plot(history['acc'])\n",
    "    plt.plot(history['val_acc'])\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Verification'], loc=0)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def plot_loss(history, title=None):\n",
    "    if not isinstance(history, dict):\n",
    "        history = history.history\n",
    "\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Verification'], loc=0)\n",
    "    # plt.show()\n",
    "    \n",
    "def main():\n",
    "    Nin = 784\n",
    "    Nh = 100\n",
    "    number_of_class = 10\n",
    "    Nout = number_of_class\n",
    "\n",
    "    # model = ANN_models_func(Nin, Nh, Nout)\n",
    "    # model = ANN_models_class(Nin, Nh, Nout)\n",
    "    model = ANN_model(Nin, Nh, Nout)\n",
    "    (X_train, Y_train), (X_test, Y_test) = Data_func()\n",
    "\n",
    "    history = model.fit(X_train, Y_train, epochs=15, batch_size=100, validation_split=0.2)\n",
    "    performace_test = model.evaluate(X_test, Y_test, batch_size=100)\n",
    "    print('Test Loss and Accuracy ->', performace_test)\n",
    "\n",
    "    plot_loss(history)\n",
    "    plt.show()\n",
    "    plot_acc(history)\n",
    "    plt.show()\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
