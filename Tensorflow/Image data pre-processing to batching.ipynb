{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "data\\trainingSet\\2\\img_32697.jpg\n",
      "28\n",
      "<class 'numpy.ndarray'>\n",
      "<PIL.Image.Image image mode=I size=28x28 at 0x1DDE44C94A8>\n",
      "Tensor(\"resize_images/Squeeze:0\", shape=(28, 28, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "#https://medium.com/trackin-datalabs/data-input-%EB%A7%8C%EB%93%A4%EA%B8%B0-74bb5c1ce52f\n",
    "\n",
    "#전처리 기술\n",
    "data_list = glob('data\\\\trainingSet\\\\*\\\\*.jpg') \n",
    "\n",
    "\n",
    "def get_label_from_path(path):\n",
    "    return int(path.split('\\\\')[-2])\n",
    "\n",
    "def read_image(path):\n",
    "    image = np.array(Image.open(path))\n",
    "    print(path)\n",
    "    print(image.shape[0])\n",
    "    print(type(image))\n",
    "    return image.reshape(image.shape[0], image.shape[1])\n",
    "\n",
    "label_name_list= []\n",
    "\n",
    "for path in data_list:\n",
    "    label_name_list.append(get_label_from_path(path))\n",
    "    \n",
    "\n",
    "#원핫인코딩\n",
    "\n",
    "unique_label_names = np.unique(label_name_list)\n",
    "def onehot_encode_label(path):\n",
    "    onehot_label = unique_label_names == get_label_from_path(path)\n",
    "    onehot_label = onehot_label.astype(np.uint8)\n",
    "    return onehot_label\n",
    "\n",
    "link = data_list[11311]\n",
    "print(get_label_from_path(link))\n",
    "read_im = read_image(link)\n",
    "pi = Image.fromarray(np.int32(read_im))\n",
    "print(pi)\n",
    "## pi.show()\n",
    "\n",
    "\n",
    "#배치만들기\n",
    "import tensorflow as tf\n",
    "\n",
    "def _read_py_function(path, label):\n",
    "    image = read_image(path)\n",
    "    label = np.array(label, dtype=np.uint8)\n",
    "    return image.astype(np.int32), label\n",
    "\n",
    "def _resize_function(image_decoded, label):\n",
    "    image_decoded.set_shape([None, None, None])\n",
    "    image_resized = tf.image.resize_images(image_decoded, [28, 28])\n",
    "    print(image_resized)\n",
    "    return image_resized, label\n",
    "\n",
    "# label을 array 통채로 넣는게 아니고, list 화 시켜서 하나씩 넣기 위해 list로 바꿔주었다. \n",
    "\n",
    "batch_size =500\n",
    "label_list = [onehot_encode_label(path).tolist() for path in data_list]\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data_list, label_list))\n",
    "dataset = dataset.map(lambda data_list, label_list: tuple(tf.py_func(_read_py_function, [data_list, label_list], [tf.int32, tf.uint8])))\n",
    "#tf.py_func -> 인수1: 처리할 함수 인수2: 입력값 인수3: 반환형식\n",
    "dataset = dataset.map(_resize_function)\n",
    "dataset = dataset.repeat(100) #epoch 의 수를 정한다\n",
    "dataset = dataset.shuffle(buffer_size=(int(len(data_list) * 0.4) + 3 * batch_size)) # 섞을 정도\n",
    "\n",
    "dataset = dataset.batch(batch_size)# 아주 편리한 배치만들기 방식\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "image_stacked, label_stacked = iterator.get_next()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
